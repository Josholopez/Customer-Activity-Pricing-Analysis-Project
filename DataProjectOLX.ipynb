{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import the packages and load the XLSX file with Pandas",
   "id": "f3a9c5b3cef0924f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-08T13:43:18.880409Z",
     "start_time": "2025-09-08T13:43:18.086631Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "file_path = \"/Users/joshlopez/PyCharmMiscProject/NP_task_eng_revised.xlsx\"\n",
    "df1 = pd.read_excel(file_path, sheet_name='Data_1')\n",
    "df2 = pd.read_excel(file_path, sheet_name='Data_2')\n"
   ],
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1.  inspection data types",
   "id": "b21ee9942042dd2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:43:18.900872Z",
     "start_time": "2025-09-08T13:43:18.893435Z"
    }
   },
   "cell_type": "code",
   "source": "print(df1.dtypes)",
   "id": "8cee7348fd58c797",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX                    object\n",
      "country_code              object\n",
      "region_id                 object\n",
      "first_activity            object\n",
      "last_activity     datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Convert to correct data types",
   "id": "7716fd18b9cab8bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:43:18.948221Z",
     "start_time": "2025-09-08T13:43:18.936241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df1[\"first_activity\"] = pd.to_datetime(df1[\"first_activity\"], errors='coerce')\n",
    "df1['region_id'] = pd.to_numeric(df1['region_id'], errors='coerce')\n",
    "print(df1.dtypes)"
   ],
   "id": "7c3c548f89ce7138",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX                    object\n",
      "country_code              object\n",
      "region_id                float64\n",
      "first_activity    datetime64[ns]\n",
      "last_activity     datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Connect to SQLite3",
   "id": "77715859c4e974a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:43:19.018348Z",
     "start_time": "2025-09-08T13:43:18.961952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn = sqlite3.connect(\"my_database.db\")\n",
    "df1.to_sql(\"Data_1\", conn, index=False, if_exists='replace')\n",
    "current_year = datetime.now().year"
   ],
   "id": "96d2b3e6c9d2eff5",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Create a new tables with anomaly flags",
   "id": "c704bc2020b1a288"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:43:19.052042Z",
     "start_time": "2025-09-08T13:43:19.025610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "SELECT *,\n",
    "CASE\n",
    "  WHEN PREFIX IS NULL AND CAST(strftime('%Y',first_activity) AS INTEGER) > 2025 THEN 'Future Dates + Missing PREFIX'\n",
    "  WHEN PREFIX IS NULL THEN 'Missing PREFIX'\n",
    "  WHEN PREFIX IN (SELECT PREFIX from Data_1 GROUP BY PREFIX HAVING count(*)>1) THEN 'Duplicate PREFIX'\n",
    "  WHEN last_activity < first_activity THEN 'Invalid Dates'\n",
    "  WHEN LENGTH(country_code) <> 2 THEN 'Invalid Country'\n",
    "  WHEN region_id IS NULL AND first_activity IS NULL THEN 'Missing date + Invalid Region'\n",
    "  WHEN region_id <=0 OR region_id IS NULL THEN 'Invalid Region'\n",
    "  ELSE 'OK'\n",
    "  END AS issue\n",
    "FROM Data_1\n",
    "\"\"\"\n",
    "\n",
    "df_with_issues = pd.read_sql(query, conn)"
   ],
   "id": "3db6154ec46a6a2d",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1.1 Anomalies from the Data_1 table\n",
    "\n",
    "The approach used was:\n",
    "- Identify the data types of each column.\n",
    "- Identify missing or null values.\n",
    "- Set rules for outliers, for instance dates in the future, duplicated values, and length of the value out of the expected range.\n",
    "- Create a column displaying the anomalies to be shared with the team in order to fix the issues."
   ],
   "id": "b1afeb77faab6194"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:43:19.078589Z",
     "start_time": "2025-09-08T13:43:19.062344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "issues_only = df_with_issues[df_with_issues[\"issue\"] != 'OK']\n",
    "print(issues_only)"
   ],
   "id": "8450626fa3806ff8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      PREFIX country_code  region_id       first_activity  \\\n",
      "159     14fd695f545x537ab749           PL       23.0  2015-09-27 13:55:12   \n",
      "169     14fd695f545x537ab749           PL       11.0  2015-10-07 15:58:21   \n",
      "728     14fd7a9d90ex1626dc75           RO        3.0  2015-11-20 10:21:01   \n",
      "844     14fd7a9d90ex1626dc75           PL        4.0  2015-09-21 18:00:58   \n",
      "2068  14fe06679c7x375369ds4c           PL        NaN                 None   \n",
      "2240    14fd6247ce1x19dc5f27           PL       13.0  2015-09-29 23:30:47   \n",
      "2276    14fd6247ce1x19dc5f27           PL        1.0  2015-09-19 20:39:39   \n",
      "2353                    None           PL       23.0  2040-12-20 07:39:42   \n",
      "\n",
      "            last_activity                          issue  \n",
      "159   2015-09-27 13:55:12               Duplicate PREFIX  \n",
      "169   2015-10-07 15:58:21               Duplicate PREFIX  \n",
      "728   2015-11-20 10:21:01               Duplicate PREFIX  \n",
      "844   2015-09-21 18:00:58               Duplicate PREFIX  \n",
      "2068  2015-11-17 22:38:50  Missing date + Invalid Region  \n",
      "2240  2015-09-27 23:30:47               Duplicate PREFIX  \n",
      "2276  2015-10-01 16:23:51               Duplicate PREFIX  \n",
      "2353  2040-12-20 07:39:42  Future Dates + Missing PREFIX  \n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1.2 Quantitative and percentage distribution of user by region\n",
    "\n",
    "The most represented region in this data is region_id 2.0 with 13.67% of users\n",
    "in contrast the least represented region is region_id 23.0 with 0.04% of users."
   ],
   "id": "174dbfcc35119bf1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:43:19.131729Z",
     "start_time": "2025-09-08T13:43:19.114181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query2 = \"\"\"\n",
    "SELECT region_id,\n",
    "count(*) AS user_count,\n",
    "ROUND(count(*)*100.0/(select count(*) from Data_1),2) AS percentage\n",
    "FROM Data_1\n",
    "WHERE region_id IS NOT NULL\n",
    "GROUP BY region_id\n",
    "ORDER BY percentage desc\n",
    "\"\"\"\n",
    "\n",
    "df_2_tasks = pd.read_sql(query2, conn)\n",
    "print(df_2_tasks)"
   ],
   "id": "bf5e3c2f948e2d0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    region_id  user_count  percentage\n",
      "0         2.0         684       13.67\n",
      "1         6.0         575       11.49\n",
      "2         1.0         573       11.45\n",
      "3         3.0         388        7.75\n",
      "4         4.0         366        7.31\n",
      "5         7.0         341        6.81\n",
      "6         5.0         332        6.63\n",
      "7        15.0         303        6.05\n",
      "8         8.0         280        5.59\n",
      "9        11.0         236        4.72\n",
      "10       17.0         197        3.94\n",
      "11       14.0         181        3.62\n",
      "12       13.0         168        3.36\n",
      "13        9.0         152        3.04\n",
      "14       18.0         128        2.56\n",
      "15       12.0          98        1.96\n",
      "16       23.0           2        0.04\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1.3 Percentage of user who only did one activity and never came back\n",
    "\n",
    "The percentage of user who did only one activity is 44.06%"
   ],
   "id": "a981187143600b71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:43:19.167938Z",
     "start_time": "2025-09-08T13:43:19.158466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SQL approach\n",
    "query3 = \"\"\"\n",
    "SELECT ROUND((SELECT count(*) FROM Data_1 WHERE first_activity=last_activity)*100.0\n",
    "/ (SELECT count(*) FROM Data_1 WHERE first_activity IS NOT NULL AND last_activity IS NOT NULL),2) AS perc_unique_users\n",
    "\"\"\"\n",
    "df_3_tasks = pd.read_sql(query3, conn)\n",
    "print(df_3_tasks)\n"
   ],
   "id": "aea284eedee673ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   perc_unique_users\n",
      "0              44.06\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1.4 List of customers that did only 1 activity\n",
    "\n",
    "The way of identifying the customers who did only one activity is by comparing the columns first_activity and last_activity for prefix with the same values in both columns\n",
    "\n",
    "The answer is a total of 2205 unique customers."
   ],
   "id": "994fc7e9a3888a97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:43:19.208973Z",
     "start_time": "2025-09-08T13:43:19.196674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query4 = \"\"\"\n",
    "SELECT PREFIX FROM Data_1 WHERE first_activity=last_activity\n",
    "\"\"\"\n",
    "df_4_tasks = pd.read_sql(query4, conn)\n",
    "print(df_4_tasks)"
   ],
   "id": "2d60bd3936ce2a13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    PREFIX\n",
      "0     125e7c32c75x1470d378\n",
      "1     137178d76e7x697d40d9\n",
      "2     13951d78ccax69d403c1\n",
      "3     14fc1cfc985x33fe98a6\n",
      "4     14fd4c69808x72b705a7\n",
      "...                    ...\n",
      "2200  14fd59804f0x10529bc8\n",
      "2201  14fe196266fx621c950d\n",
      "2202   14fe19e2cffxded6c21\n",
      "2203  14fe1ae473ax5ae7e122\n",
      "2204   14fe1b040e1xa171172\n",
      "\n",
      "[2205 rows x 1 columns]\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1.5 Actions suggested to activate users who did only one activity\n",
    "\n",
    "I will provide the specific list of users and details to the Marketing team and also managers in charge of customer retention and I would advise them to set a customized marketing campaign for these users with attractive coupons or discounts for accessing the site once again and purchasing the first item, the campaign can be also target the concentration of users in certain regions."
   ],
   "id": "cb938dd3d914e9b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
